# -*- coding: utf-8 -*-
"""ArcFace ile Yüz Tanıma.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-L-BFiVRK01-s3TZRm_N4qt0Qvo9Ey1o

##Kütüphaneler
"""

import os
from pathlib import Path
from tqdm import tqdm
from easydict import EasyDict as dict

import torch
import torch.nn as nn
import torch.optim as optim


from data.ms1m import get_train_loader
from data.lfw import LFW

from backbone.arcfacenet import SEResNet_IR
from margin.ARCMarginProduct import ArcMarginProduct

from util.utils import save_checkpoint, test

"""##Konfigürasyon"""

conf = edict()

conf.train_root ='.dataset/MS1M'
conf.lfw_test_root = '.dataset/lfw_aligned_112'
conf.lfw_file_list = '.dataset/lfw_pair.txt'

conf.mode ='ir'#'ir'
conf.depth = 100
conf.margin_type = 'ArcFace'
conf.feature_Dim = 512
conf.scale_Siz = 32.0
conf.batch_size = 96 #16
conf.lr = 0.01
conf.milestones =[8,10,12]
conf.total_epoch = 14

conf.save_folder = './ saved'
conf.save_dir = os.path.join(conf.save_folder,conf.mode+'_' + str(conf.depth)) #./saved/ se_ir_50
conf.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
conf.num_workers = 4
conf.pin_memory = True

os.makedirs(conf.save_dir,exist_ok = True)

"""##Veri Yükleme"""

transform = trans.Compose([
     trans.ToTEnseor(),#range[0,255] -> [0.0,1.0]
     trans.Normalize(mean=(0.5,0.5,0.5), std =(0.5,0.5,0.5))
 ])

trainloader, class_num = get_train_loader(conf)

print('number of id:', class_num)

print(trainloader.dataset)

lfwdataset = LFW(conf.lfw_test_root, conf.lfw_file_list, transform = transform)
lfwloader = torch.utils.data.DataLoader(lfwdataset, batch_size = 128, num_workers = conf.num_workes)

"""##Model"""

print(conf.device)

net = SEResNet_IR(conf.depth, geature_dim = conf.feature_dim, mode = conf.mode).to(conf.device)
margin = ArcMarginProduct(conf.feature_dim, class_num).to(conf.device)

print(net)

criterion = nn.CrossEntropyLoss()

optimizer = optim.SGD([
    {'params': net.parameters(), 'weight_decay': 5e-4},
    {'params': margin.parameters(), 'weight_decay':5e-4}
], lr=conf.lr,momentum = 0.9, nesterov=True)

def schedule_lr():
  for params in optimizer.param_groups:
    params['lr']/= 10
  print(optimizer)

"""##Eğitim"""

best_acc = 0

for epoch in range(1, conf.total_epoch+1):

    net.train()

    print('epoch {}/{}'.format(epoch, conf.total_epoch))

    if epoch == conf.milestones[0]:
      schedule_lr()
    if epoch == conf.milestones[1]:
      schedule_lr()
    if epoch == conf.milestones[2]:
      schedule_lr()

    for data in tqdm(trainloader):
      img, label =data[0].to(conf.device), data[1].to(conf.device)
      optimizer.zero_grad()

      logist = net(img)
      output = margin(logist,label)
      total_loss = criterion(output,label)
      total_loss.backward()
      optimizer.step()

      #test

      net.eval()

      lfw_acc = test(conf, test, lfwdataset, lfwloader)

      print('\nLFW: {:,4f} | train_loss: {:,4f}\n'.format(lfw_acc, total_loss.item()))
      is_best = lfw_acc > best_acc
      best_acc = max(lfw_acc, best_acc)

      save_checkpoint({
        'epoch':epoch,
        'net_state_dict': net.state_dict(),
        'margin_state_dict': margin.state_dict(), 
        'best_acc':best_acc 

      },is_best, checkpoint = conf.save_dir)
      
      #modelin kaydedilmesi